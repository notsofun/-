{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id             question  \\\n",
      "0  198         你有固定的生活仪式感吗？   \n",
      "1    7        你有收藏什么东西的习惯吗？   \n",
      "2  107  你曾经因为太社恐干过最离谱的事是什么？   \n",
      "3   28       你更喜欢逛书店还是逛博物馆？   \n",
      "4  291   你觉得自己是个恋爱忠诚度极高的人吗？   \n",
      "\n",
      "                                            response            questions  \\\n",
      "0  是的，我有固定的生活仪式感，比如每天早上5点起床，晚上10点睡觉，每餐后立即运动。这让我感觉...         你有固定的生活仪式感吗？   \n",
      "1  是的，我有收藏的习惯，尤其是那些特别设计的古董，比如老照片、古玩书、艺术品等，这些都让我觉得...        你有收藏什么东西的习惯吗？   \n",
      "2    曾经让你感到无比紧张的时刻，比如结伴而入，但之后又离开，或者在公共场所说话时却紧张得不知所措。  你曾经因为太社恐干过最离谱的事是什么？   \n",
      "3                  逛书店更吸引人，因为它有更多的书籍，书包里可以放很多东西，更方便。       你更喜欢逛书店还是逛博物馆？   \n",
      "4  如果你觉得自己是个恋爱忠诚度极高的人，可能是因为你对伴侣有深厚的感情，愿意付出太多，甚至有时...   你觉得自己是个恋爱忠诚度极高的人吗？   \n",
      "\n",
      "                                             answers  \n",
      "0                                    有，比如睡前点个香薰或者泡茶。  \n",
      "1     有！我特别喜欢收集书签，每次看到都会忍不住想带回家。你呢？有没有什么让你忍不住收藏的小癖好？  \n",
      "2                                    装作没看见熟人，硬生生走错路。  \n",
      "3  两者都有魅力，但我觉得逛书店时那种探索未知世界的感觉更吸引我。每一本书都是一个小宇宙，特别喜...  \n",
      "4                                           是，专一且长情。  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_generated = pd.read_csv('/Users/huangzhidian/Desktop/Chatbot项目/generated_results_finetued_1st_revised.csv')\n",
    "df_standard = pd.read_csv('/Users/huangzhidian/Desktop/Chatbot项目/评测集_带回答.csv')\n",
    "\n",
    "\n",
    "merged_df = pd.merge(df_generated,df_standard,on='id')\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # 轻量级模型，可本地运行\n",
    "\n",
    "# question = \"你有没有一首歌是“完全听不懂但很喜欢”？\"\n",
    "# reference_answer = \"有，比如一些纯音乐或异国歌曲。\"\n",
    "# candidate_answer = \"嗯，你说的那也是我呢，好像有些歌我都没听懂。\"\n",
    "\n",
    "# emb1 = model.encode(reference_answer, convert_to_tensor=True)\n",
    "# emb2 = model.encode(candidate_answer, convert_to_tensor=True)\n",
    "\n",
    "# score = util.pytorch_cos_sim(emb1, emb2)\n",
    "# print(score.item())  # 值越接近 1，表示语义越相近\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# 加载 SBERT 模型\n",
    "sbert_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "# 计算语义相似度的函数\n",
    "def compute_sbert_similarity(question, reference, candidate):\n",
    "    # **批量编码，提高效率**\n",
    "    embeddings = sbert_model.encode([question, reference, candidate], convert_to_tensor=True)\n",
    "\n",
    "    q_embedding, r_embedding, c_embedding = embeddings  # 解包\n",
    "\n",
    "    # **计算余弦相似度**\n",
    "    sim_r = util.pytorch_cos_sim(c_embedding, r_embedding).item()  # 候选回答 vs 参考答案\n",
    "    sim_q = util.pytorch_cos_sim(c_embedding, q_embedding).item()  # 候选回答 vs 问题本身（防止无关回答）\n",
    "\n",
    "    return (sim_r + sim_q) / 2  # 平均相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# **加载 Fine-tuned BERT 模型**（用于分类任务）\n",
    "model_name = \"Zhidian2025/bert-base-chinese-logitrelevancy-finetuned\"  # 这里换成你 Fine-tuned 的模型\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_final_score(row):\n",
    "    question = row[\"question\"]\n",
    "    reference = row[\"answers\"]\n",
    "    candidate = row[\"response\"]\n",
    "\n",
    "    # **Step 1: 计算 SBERT 相似度**\n",
    "    sbert_score = compute_sbert_similarity(question, reference, candidate)\n",
    "\n",
    "    # **Step 2: Fine-tuned BERT 分类（回答是否相关）**\n",
    "    inputs = tokenizer(question, candidate, return_tensors=\"pt\")\n",
    "\n",
    "    inputs[\"input_ids\"] = inputs[\"input_ids\"].clamp(0, model.config.vocab_size - 1)\n",
    "    # **确保数据在相同设备上**\n",
    "    inputs = {key: value.to(model.device) for key, value in inputs.items()}\n",
    "\n",
    "    # **前向传播计算 logits**\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "\n",
    "    # **获取 \"回答正确\" 概率**\n",
    "    answer_validity = torch.softmax(logits, dim=-1)[0, 1].item()\n",
    "\n",
    "    # **Step 3: 计算最终综合评分**\n",
    "    alpha = 0.7  # 语义相似度权重\n",
    "    final_score = alpha * sbert_score + (1 - alpha) * answer_validity\n",
    "\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "评分成功！\n"
     ]
    }
   ],
   "source": [
    "# **将模型移动到 GPU（如果可用）**\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# **在 DataFrame 中应用评分计算**\n",
    "merged_df[\"FinalScore\"] = merged_df.apply(compute_final_score, axis=1)\n",
    "print('评分成功！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['FinalScore'] = merged_df['FinalScore'].apply(lambda x: x.item() if hasattr(x, 'item') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id  FinalScore\n",
      "count   50.000000   50.000000\n",
      "mean   165.840000    0.586390\n",
      "std     92.007622    0.101589\n",
      "min      2.000000    0.355968\n",
      "25%     95.750000    0.519339\n",
      "50%    160.000000    0.586472\n",
      "75%    254.000000    0.657442\n",
      "max    299.000000    0.805760\n"
     ]
    }
   ],
   "source": [
    "# 输出结果\n",
    "print(merged_df.describe())\n",
    "\n",
    "merged_df.to_csv('Evalution_1st_revised_finetuned.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
